{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project resume\n",
    "\n",
    "En este trabajo de ML se crea un modelo para predecir el valor de vehículos de reventa según sus especificacione técnicas y datos de uso anterior.  \n",
    "\n",
    "Comenzando por la importación de datos, se trata de un dataframe extraido de Kaggle, en el que encontramos algo menos de 6.000 filas con  \n",
    "la información dividida en 8 columnas: marca y modelo del vehículo, ciudad en la que está a la venta, año de fabricación, kilómetros  \n",
    "hechos, tipo de combustible, tipo de transmisión, de que 'mano' es, es decir, si quien lo vende ha sido su único dueño o el número de dueños previos, consumo, caballos, número de asientos, precio cuando era nuevo y precio actual de venta.\n",
    "\n",
    "Tras en análisis inicial podemos observar que es un dataframe bastante limpio, como es de esperar cuando viene de Kaggle. Tiene pocos datos faltantes. \n",
    "Haciendo un estudio de Nans por columna vemos que los datos de precio original son, casi es su totalidad, nulos, por lo que se deshecha esa columna.\n",
    "\n",
    "Para hacer más valiosa la visualización se opta por limpiar el dataframe y realizar las transformaciones pertienetes antes de comenzar con el EDA. Se realizaron algunas pruebas a parte para llegar a esta decisión.\n",
    "\n",
    "Se crea, a partir de la columna 'name', dos columnas, llamadas 'marca' y 'modelo', para facilitar la labor más adelante.\n",
    "\n",
    "Las columnas 'mileage', 'engine' y 'power' contienen datos numéricos valiosos pero son tipo object y tienen letras, por lo que estas se eliminan y se pasan a numérico.\n",
    "\n",
    "Posteriormente se hace un mapeo a las columnas 'fuel_type', 'transmission' y 'owner_type', para poder añadir esos datos al modelo. Se opta por un mapeo ya que son datos sencillos y para poder ordenar manualmente los distintos tipos de dueño.\n",
    "\n",
    "Se pasa a euros la columna 'price', que será nuestro target, para evitar al lector hacer conversiones una vez hecha la predicción y facilitar la comprensión del resultado.\n",
    "\n",
    "Usando la columna 'model' creada más arriba, se hace groupby para imputar datos faltantes en 'engine', 'power, 'seats' y 'mileage'. En las tres primeras se imputa la mediana de cada modelo y el la última la media.\n",
    "\n",
    "Se valora dar un uso a la columna 'location', quizá haciendo un LabelEncoder, pero finalmente se concluye que no aportará nada de valor al modelo, por lo que se elimina junto a 'name', 'brand' y 'model'.\n",
    "\n",
    "Al hacer el histplot se detecta que la columna 'kilometers_driven' tiene algunos outliers que desbalancean, por lo que se eliminan.\n",
    "\n",
    "Se guarda el dataframe procesado para pasar a las visualizaciones.\n",
    "\n",
    "\n",
    "## EDA\n",
    "\n",
    "Se comienza por hacer un pairplot.\n",
    "\n",
    "Después se hace un heatmap, para entender la relación entre variables, cómo se influyen y si son o no dependientes.\n",
    "\n",
    "Finalmente se realiza un hist para ver la distribución de cada variable y poder decidir la mejor manera de abordar el Feature Engineering que viene a continuación.\n",
    "\n",
    "**Se dividen los datos**\n",
    "\n",
    "\n",
    "## Escalado y dummies\n",
    "\n",
    "Se realiza un MinMaxScaler para tener todos los datos en la misma magnitud. A parte de esto, se determina que no hace falta nada más.\n",
    "\n",
    "\n",
    "## BaseLine\n",
    "\n",
    "Se prueban 5 modelos: LinearRegression, DecisionTreeRegressor, RandomForestRegressor, XGBRegressor, CatBoostRegressor. Todos ellos modelos de regresión dado el tipo de problema que tenemos que resolver.\n",
    "Como métrica se opta por MAE negativo. Se elige este porque mide cuán cerca están las predicciones de los valores reales en promedio, dando una manera visual y fácil de entender de cómo está funcionando el modelo.\n",
    "\n",
    "El mejor resultado lo devuelve el CatBoostRegressor, por lo que se continúa con este modelo.\n",
    "\n",
    "**Se procede al entrenamiento y predicción del modelo**\n",
    "\n",
    "En la validación se observa un MAE aparentemente bajo. El MAPE indica que hay un error relativamente alto, por lo que se pasa a la optimización.\n",
    "\n",
    "\n",
    "## Optimización\n",
    "\n",
    "Como hiperparámetros se usa 'depth', 'learning_rate' e 'iterations', y se refuerza el modelo con un GridSearch.\n",
    "\n",
    "## Guardado del modelo\n",
    "\n",
    "Se guarda como .plk.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
